{"title":"Data Collection Process","markdown":{"yaml":{"title":"Data Collection Process","editor_options":{"chunk_output_type":"console"}},"headingText":"Web Scraping","containsRefs":false,"markdown":"\n\n```{r, include = FALSE}\nknitr::opts_chunk$set(\n  collapse = TRUE,\n  comment = \"#>\"\n)\n```\n\nFor most projects the data collection process can be done manually and later attache the file in a folder but that isn't a option when we are working with **big data**.\n\nTo solve this problem, we have created the next script to automate the data collection process so the project could be reproduced easily just by running the code below.\n\n\n\nTo always have a updated list of 2022 and 2023 links of **High Volume For-Hire Vehicles** documents let's scrape the [TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page) by using the `rvest` library.\n\n### Downloading source page\n\n```{r SourcePage}\nSourcePage <-\n  rvest::read_html(\"https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\")\n```\n\n\n### Getting links for taxi trips\n\n```{r getting-trip-links}\nTripLinks <-\n  SourcePage |>\n  rvest::html_elements(xpath = '//div[@class=\"faq-answers\"]//li/a') |>\n  rvest::html_attr(\"href\") |>\n  grep(pattern = \"fhvhv_[a-z]+_202[23]-\\\\d{2}\\\\.parquet\", value = TRUE) |>\n  trimws() |>\n  sort()\n\nFileNames <- basename(TripLinks)\n\nFileNames\n```\n\n### Getting link for trip zones.\n\n```{r getting-taxi-zone-link}\nTaxiZoneLink <-\n  SourcePage |>\n  rvest::html_elements(xpath = '//ul/li/a[text()=\"Taxi Zone Lookup Table\"]')  |>\n  rvest::html_attr(\"href\") |>\n  trimws()\n\nTaxiZoneLink\n```\n\n```{r getting-taxi-zone-shapes-link}\nTaxiZoneShapesLink <-\n  SourcePage |>\n  rvest::html_elements(xpath = '//ul/li/a[text()=\"Taxi Zone Shapefile\"]')  |>\n  rvest::html_attr(\"href\") |>\n  trimws()\n\nTaxiZoneShapesLink\n```\n\n## Saving trips data\n\nTo take advantage of the best capacities of `Duckdb` we need save a each parquet file in folder with useful information to filter later, that why we will have one folder level related to years the next sub-folders related to a month with each parquet with the name `part-0.parquet` by following process.\n\n### Defining folder paths\n\n```{r data-paths}\nSourcePath <- here::here()\n\nRawDataPath <- file.path(SourcePath, \"raw-data\")\n\nParquetFolderPath <- file.path(RawDataPath, \"trip-data\")\n\nYearFoldersPath <- \n  gsub(x = FileNames,\n       pattern = \"^fhvhv_tripdata_|-\\\\d{2}\\\\.parquet$\",\n       replacement = \"\") |>\n  paste0(\"year=\", a = _) |>\n  unique() |>\n  file.path(ParquetFolderPath, a = _)\n\n```\n\n### Creating folders to use\n\n```{r creating-folders}\nfor(paths in c(RawDataPath, ParquetFolderPath, YearFoldersPath)) {\n  \n  if(!file.exists(paths)){\n    dir.create(paths)\n  }\n  \n}\n```\n\n### Defining the sub-folders to split the files based on year.\n\n```{r parsermd-chunk-5, eval=FALSE}\nfor(year_i in YearFoldersPath) dir.create(year_i, showWarnings = FALSE)\n```\n\n### Creating a folder for each month\n\n```{r parsermd-chunk-6, eval=FALSE}\nMonthFolders <- gsub(\n  x = FileNames,\n  pattern = \"^fhvhv_tripdata_\\\\d{4}-|\\\\.parquet$\",\n  replacement = \"\"\n) |>\n  paste0(\"month=\", a = _)\n\nMonthFoldersPath <- file.path(ParquetFolderPath, YearFolders, MonthFolders)\n\nfor(month_i in MonthFoldersPath) dir.create(month_i, showWarnings = FALSE)\n```\n\n### Downloading each file on each folder\n\n```{r eval=FALSE}\n# Parquet files might time a longer time to be downloaded\noptions(timeout = 1800)\n\n\n# Parquet trip data\nfor(link_i in seq_along(TripLinks)){\n  \n  download.file(TripLinks[link_i],\n                destfile = file.path(MonthFoldersPath[link_i],\"part-0.parquet\"),\n                mode = \"wb\")\n  \n}\n\n\n# Taxi Zone CSV\ndownload.file(TaxiZoneLink,\n              destfile = file.path(RawDataPath,\"taxi_zone_lookup.csv\"),\n              mode = \"wb\")\n\n# Taxi Zone Shapes\ndownload.file(TaxiZoneShapesLink,\n              destfile = file.path(RawDataPath,\"taxi_zones.zip\"),\n              mode = \"wb\")\n```\n\n### Unziping zone shapes\n\n```{r eval=FALSE}\nunzip(\n  zipfile = file.path(RawDataPath,\"taxi_zones.zip\"),\n  exdir = file.path(RawDataPath,\"taxi_zones\")\n)\n\nfile.remove(file.path(RawDataPath,\"taxi_zones.zip\"))\n```\n\n\n## Saving results in a database\n\nDespite that parquet files are great for sharing big data files keeping save the format for each format, it presents problems if we need to apply **sampling operations**.\n\nTo work with data large than RAM, we will need to create a simple data base with `duckdb` by following the next simple steps.\n\n1. Listing all files to read.\n\n```{r}\nParquetSource <-\n  list.files(ParquetFolderPath,\n             recursive = TRUE,\n             full.names = TRUE) |>\n  paste0(\"'\", a = _ ,\"'\") |> \n  paste0(collapse = \", \") |>\n  paste0(\"read_parquet([\", a = _ ,\"])\")\n\nParquetSource\n```\n\n2. Creating a connection.\n\n```r\ncon <- DBI::dbConnect(duckdb::duckdb(), \n                      dbdir = here::here(\"output/my-db.duckdb\"))\n```\n\n3. Saving all files in the database after adding an id to differentiate between trips and adding the performance per our each trips.\n\n```r\nNycTripsCreateTable <- glue::glue_safe(\"\nCREATE TABLE NycTrips AS\n    SELECT \n        ROW_NUMBER() OVER () AS trip_id,\n        *,\n        (driver_pay + tips) / (trip_time / 3600) AS performance_per_hour\n    FROM {ParquetSource}\n\")\n\nDBI::dbExecute(con, NycTripsCreateTable)\n```\n\n4. Disconnecting the data base.\n\n```r\nDBI::dbDisconnect(con, shutdown = TRUE)\n\nrm(con)\n```\n\n\n5. After saving the data in the data base we can confirm its final size.\n\n```{r}\nhere::here(\"output/my-db.duckdb\") |>\n  file.size() |>\n  structure(class = \"object_size\") |>\n  format(units = \"auto\")\n```\n\n","srcMarkdownNoYaml":"\n\n```{r, include = FALSE}\nknitr::opts_chunk$set(\n  collapse = TRUE,\n  comment = \"#>\"\n)\n```\n\nFor most projects the data collection process can be done manually and later attache the file in a folder but that isn't a option when we are working with **big data**.\n\nTo solve this problem, we have created the next script to automate the data collection process so the project could be reproduced easily just by running the code below.\n\n\n## Web Scraping\n\nTo always have a updated list of 2022 and 2023 links of **High Volume For-Hire Vehicles** documents let's scrape the [TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page) by using the `rvest` library.\n\n### Downloading source page\n\n```{r SourcePage}\nSourcePage <-\n  rvest::read_html(\"https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\")\n```\n\n\n### Getting links for taxi trips\n\n```{r getting-trip-links}\nTripLinks <-\n  SourcePage |>\n  rvest::html_elements(xpath = '//div[@class=\"faq-answers\"]//li/a') |>\n  rvest::html_attr(\"href\") |>\n  grep(pattern = \"fhvhv_[a-z]+_202[23]-\\\\d{2}\\\\.parquet\", value = TRUE) |>\n  trimws() |>\n  sort()\n\nFileNames <- basename(TripLinks)\n\nFileNames\n```\n\n### Getting link for trip zones.\n\n```{r getting-taxi-zone-link}\nTaxiZoneLink <-\n  SourcePage |>\n  rvest::html_elements(xpath = '//ul/li/a[text()=\"Taxi Zone Lookup Table\"]')  |>\n  rvest::html_attr(\"href\") |>\n  trimws()\n\nTaxiZoneLink\n```\n\n```{r getting-taxi-zone-shapes-link}\nTaxiZoneShapesLink <-\n  SourcePage |>\n  rvest::html_elements(xpath = '//ul/li/a[text()=\"Taxi Zone Shapefile\"]')  |>\n  rvest::html_attr(\"href\") |>\n  trimws()\n\nTaxiZoneShapesLink\n```\n\n## Saving trips data\n\nTo take advantage of the best capacities of `Duckdb` we need save a each parquet file in folder with useful information to filter later, that why we will have one folder level related to years the next sub-folders related to a month with each parquet with the name `part-0.parquet` by following process.\n\n### Defining folder paths\n\n```{r data-paths}\nSourcePath <- here::here()\n\nRawDataPath <- file.path(SourcePath, \"raw-data\")\n\nParquetFolderPath <- file.path(RawDataPath, \"trip-data\")\n\nYearFoldersPath <- \n  gsub(x = FileNames,\n       pattern = \"^fhvhv_tripdata_|-\\\\d{2}\\\\.parquet$\",\n       replacement = \"\") |>\n  paste0(\"year=\", a = _) |>\n  unique() |>\n  file.path(ParquetFolderPath, a = _)\n\n```\n\n### Creating folders to use\n\n```{r creating-folders}\nfor(paths in c(RawDataPath, ParquetFolderPath, YearFoldersPath)) {\n  \n  if(!file.exists(paths)){\n    dir.create(paths)\n  }\n  \n}\n```\n\n### Defining the sub-folders to split the files based on year.\n\n```{r parsermd-chunk-5, eval=FALSE}\nfor(year_i in YearFoldersPath) dir.create(year_i, showWarnings = FALSE)\n```\n\n### Creating a folder for each month\n\n```{r parsermd-chunk-6, eval=FALSE}\nMonthFolders <- gsub(\n  x = FileNames,\n  pattern = \"^fhvhv_tripdata_\\\\d{4}-|\\\\.parquet$\",\n  replacement = \"\"\n) |>\n  paste0(\"month=\", a = _)\n\nMonthFoldersPath <- file.path(ParquetFolderPath, YearFolders, MonthFolders)\n\nfor(month_i in MonthFoldersPath) dir.create(month_i, showWarnings = FALSE)\n```\n\n### Downloading each file on each folder\n\n```{r eval=FALSE}\n# Parquet files might time a longer time to be downloaded\noptions(timeout = 1800)\n\n\n# Parquet trip data\nfor(link_i in seq_along(TripLinks)){\n  \n  download.file(TripLinks[link_i],\n                destfile = file.path(MonthFoldersPath[link_i],\"part-0.parquet\"),\n                mode = \"wb\")\n  \n}\n\n\n# Taxi Zone CSV\ndownload.file(TaxiZoneLink,\n              destfile = file.path(RawDataPath,\"taxi_zone_lookup.csv\"),\n              mode = \"wb\")\n\n# Taxi Zone Shapes\ndownload.file(TaxiZoneShapesLink,\n              destfile = file.path(RawDataPath,\"taxi_zones.zip\"),\n              mode = \"wb\")\n```\n\n### Unziping zone shapes\n\n```{r eval=FALSE}\nunzip(\n  zipfile = file.path(RawDataPath,\"taxi_zones.zip\"),\n  exdir = file.path(RawDataPath,\"taxi_zones\")\n)\n\nfile.remove(file.path(RawDataPath,\"taxi_zones.zip\"))\n```\n\n\n## Saving results in a database\n\nDespite that parquet files are great for sharing big data files keeping save the format for each format, it presents problems if we need to apply **sampling operations**.\n\nTo work with data large than RAM, we will need to create a simple data base with `duckdb` by following the next simple steps.\n\n1. Listing all files to read.\n\n```{r}\nParquetSource <-\n  list.files(ParquetFolderPath,\n             recursive = TRUE,\n             full.names = TRUE) |>\n  paste0(\"'\", a = _ ,\"'\") |> \n  paste0(collapse = \", \") |>\n  paste0(\"read_parquet([\", a = _ ,\"])\")\n\nParquetSource\n```\n\n2. Creating a connection.\n\n```r\ncon <- DBI::dbConnect(duckdb::duckdb(), \n                      dbdir = here::here(\"output/my-db.duckdb\"))\n```\n\n3. Saving all files in the database after adding an id to differentiate between trips and adding the performance per our each trips.\n\n```r\nNycTripsCreateTable <- glue::glue_safe(\"\nCREATE TABLE NycTrips AS\n    SELECT \n        ROW_NUMBER() OVER () AS trip_id,\n        *,\n        (driver_pay + tips) / (trip_time / 3600) AS performance_per_hour\n    FROM {ParquetSource}\n\")\n\nDBI::dbExecute(con, NycTripsCreateTable)\n```\n\n4. Disconnecting the data base.\n\n```r\nDBI::dbDisconnect(con, shutdown = TRUE)\n\nrm(con)\n```\n\n\n5. After saving the data in the data base we can confirm its final size.\n\n```{r}\nhere::here(\"output/my-db.duckdb\") |>\n  file.size() |>\n  structure(class = \"object_size\") |>\n  format(units = \"auto\")\n```\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"03-data-collection-process.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","editor":"source","theme":"cosmo","title":"Data Collection Process","editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}