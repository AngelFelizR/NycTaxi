{"title":"Data Sampling","markdown":{"yaml":{"title":"Data Sampling","editor_options":{"chunk_output_type":"console"}},"headingText":"Loading packages to use","containsRefs":false,"markdown":"\n\n```{r, include = FALSE}\nknitr::opts_chunk$set(\n  collapse = TRUE,\n  comment = \"#>\"\n)\n```\n\nAs we have a very large dataset and it doesn't include one of the target variables we want to predict, we need to apply the following steps:\n\n-   Selecting a **representative subset** of the data\n-   Adding the new target variable **`take_current_trip`**\n\nThis will help us to have more meaningful results during the *Data Understanding* phase.\n\n\n```{r warning = FALSE, message = FALSE}\n## To manage relative paths\nlibrary(here)\n\n## To import and export data frames as binary files\nlibrary(fst)\n\n## To transform data that fits in RAM\nlibrary(data.table)\nlibrary(lubridate)\n\n## To create plots\nlibrary(ggplot2)\nlibrary(ggiraph)\n\n## Custom functions\ndevtools::load_all()\n\n## Defining the print params to use in the report\noptions(datatable.print.nrows = 15, digits = 4)\n```\n\n## Sampling data to use\n\nSelecting the 0.20% of the data, aiming for around 500K samples for training and testing the model and saving the data in a binary file.\n\n``` r\n## Establishing a connection with the database\ncon <- DBI::dbConnect(duckdb::duckdb(), dbdir = here(\"output/my-db.duckdb\"))\n\n## Defining query to sample\nValidZoneSampleQuery <- glue::glue(\"\nSELECT t1.*\nFROM NycTrips t1\nINNER JOIN ZoneCodesFilter t2\n  ON t1.PULocationID = t2.PULocationID AND\n     t1.DOLocationID = t2.DOLocationID\nUSING SAMPLE 0.20% (system, 547548);\n\")\n\n## Sampling data from db\nValidZoneSample <- DBI::dbGetQuery(con, ValidZoneSampleQuery)\n\n## Closing the database connection\nDBI::dbDisconnect(con, shutdown = TRUE)\n\n## Saving results to disk\nwrite_fst(ValidZoneSample,\n          here(\"output/cache-data/ValidZoneSample.fst\"))\n```\n\n```{r echo=FALSE}\nif(!exists(\"ValidZoneSample\")){\n  ValidZoneSample <- fst::read_fst(\n    here(\"output/cache-data/ValidZoneSample.fst\"),\n    as.data.table = TRUE\n  )\n}\n```\n\n## Adding `take_current_trip` to sample\n\n### Purpose\n\nThe purpose of this variable is to compare each trip with potential trips that a taxi driver could take in the following minutes and determine if it’s better to accept the current trip request or wait for a more profitable trip in the following minutes.\n\n### Assumptions\n\nTo answer this question, we will need assumptions similar to those used in simulating a taxi driver’s decision-making process specially to select the valid trips that need to be taken in consideration to compare with.\n\nFor a trip to be considered valid, it must meet the following requirements:\n\n1.  The trip corresponds to the same company as the original trip request.\n\n2.  Only if the original trip request specified a wheelchair-accessible vehicle (WAV), future WAV trips will be eligible.\n\n3.  The trip was requested from 3 seconds (time needed to reject a trip request) up to 15 minutes after the original request time.\n\n4.  The trip start point is located in valid distance from the start point of the original trip (assuming the taxi driver is in that point) based on the relate time the trip was requested based on the request time of the original trip\n\n    -   0-1 Minute: Only 1-mile radius is valid.\n\n    -   1-3 Minutes: Expand up to 3-mile radius.\n\n    -   3-5 Minutes: Expand up to 5-mile radius.\n\n    -   Keep adding 2 miles until completing the allowed 15 minutes.\n\n### Implementation\n\nSince this process is resource-intensive and each iteration is independent, running it in parallel as a **multicore process** (supported by `future`) is optimal. This approach utilizes the full capacity of my computer, which has 8 cores and 17 GB of RAM.\n\nThe only disadvantage of this approach that my current IDE (Rstudio) don't support this process, but it can be run without issues from the **linux terminal** by writing the process on **Rscript files**.\n\nThe process was implemented in the **`add_take_current_trip()`** which has been **tested** to ensure it meets expectations, as confirmed in the [Github file](https://github.com/AngelFelizR/project.nyc.taxi/blob/master/tests/testthat/test-add_take_current_trip.R).\n\n### Tuning parallel process\n\nBefore running a process 500k times, it's important to make sure we are using the best configuration due the code and the hardware were are using.\n\nIn our case we focus in defining best values for:\n\n-   Number of cores used by `data.table`\n\n-   Number of cores used by `future`\n\n-   Chunk.size used by `future`\n\n-   Scheduling used by `future`\n\nFor that reason we have created the `R/01-fine-tune-future-process.R` script, which print the time needed for each process on the terminal after completing each one.\n\n``` bash\ndocker exec -ti Rstudio bash\ncd home/rstudio/NycTaxi\nRscript R/01-fine-tune-future-process.R\n```\n\nThe below plot summaries the obtained results.\n\n```{r}\n#| echo: false\nBenchmarkResults <- data.frame(\n  CoreConfiguration = c(\n    rep(\"Future: 7 and DT: 1 Cores\", times = 11L),\n    rep(\"Future: 4 and DT: 8 Cores\", times = 12L)\n  ),\n  Scheduling = c(\n    0.4, 0.5, 0.6, 0.4, 0.5, 0.6, 0.4, 0.5, 0.6, 0.4, 0.5,\n    0.4, 0.5, 0.6, 0.4, 0.5, 0.6, 0.4, 0.5, 0.6, 0.4, 0.5, 0.6\n  ),\n  ChunkSize = c(\n    25, 25, 25, 50, 50, 50, 100, 100, 100, 200, 200,\n    5, 25, 25, 50, 50, 50, 100, 100, 100, 200, 200, 200\n  ),\n  Duration = c(\n    528.970, 428.321, 407.558, 382.662, 384.741, 380.178, 379.015, 379.000, 377.592, 373.415, 379.463,\n    538.531, 442.395, 458.97, 424.615, 366.119, 361.745, 350.42, 347.733, 346.434, 351.716, 348.664, 358.177\n  ))\n\nBenchmarkPlot <-\n  ggplot(BenchmarkResults,\n         aes(x = ChunkSize, \n             y = Duration, \n             color = as.character(Scheduling),\n             group = interaction(Scheduling, CoreConfiguration),\n             tooltip = round(Duration,2))) +\n  geom_line() +\n  geom_point_interactive(size = 1.5) +\n  scale_y_log10() +\n  facet_wrap(vars(CoreConfiguration)) +\n  labs(title = \"Future Performance\",\n       color = \"Scheduling\",\n       y = \"Duration (s)\",\n       x = \"Chunk Size\") +\n  theme_minimal() +\n  theme(legend.position = \"top\",\n        plot.title = element_text(face = \"bold\"))\n\ngirafe(ggobj = BenchmarkPlot)\n```\n\nAnd as we can see the got better performance by using fewer cores for future, due the RAM capacity limit, when using only 4 cores and increasing the number of task per core we can see the time needed to complete the 2k samples it's reduced as it didn't use the SWAP memory while running the process, as we can see in the next screenshot.\n\n![](../figures/htop_parallel_process.png)\n\nAnd after checking this results we ended with the next configuration:\n\n-   Number of cores used by `data.table`: 8\n\n-   Number of cores used by `future`: 4\n\n-   Chunk.size used by `future`: 200\n\n-   Scheduling used by `future`: 0.6\n\n### Running process\n\nOnce we know how to set up the parallel process we need to run it month by month and save the results to avoid losing the progress in case of any process fail.\n\nAs this process was very demanding for my computer so we preferred to run each month on individual R session to avoid filling the memory by using the next __bash script__ and passing the each month as param for the __Rscript__.\n\n```{bash}\n#| eval: false\n#| file: ../R/run_add_target.sh\n```\n\nOnce defined the bash script we can use it by running the next command in the terminal.\n\n```bash\ndocker exec -ti Rstudio bash\ncd home/rstudio/NycTaxi\nbash R/run_add_target.sh R/02-add-target.R  1 24\n```\n\nHere we can see that the 24 files have been saved as fst binnary files.\n\n```{bash}\nls -lh ../output/take-trip-fst\n```\n","srcMarkdownNoYaml":"\n\n```{r, include = FALSE}\nknitr::opts_chunk$set(\n  collapse = TRUE,\n  comment = \"#>\"\n)\n```\n\nAs we have a very large dataset and it doesn't include one of the target variables we want to predict, we need to apply the following steps:\n\n-   Selecting a **representative subset** of the data\n-   Adding the new target variable **`take_current_trip`**\n\nThis will help us to have more meaningful results during the *Data Understanding* phase.\n\n## Loading packages to use\n\n```{r warning = FALSE, message = FALSE}\n## To manage relative paths\nlibrary(here)\n\n## To import and export data frames as binary files\nlibrary(fst)\n\n## To transform data that fits in RAM\nlibrary(data.table)\nlibrary(lubridate)\n\n## To create plots\nlibrary(ggplot2)\nlibrary(ggiraph)\n\n## Custom functions\ndevtools::load_all()\n\n## Defining the print params to use in the report\noptions(datatable.print.nrows = 15, digits = 4)\n```\n\n## Sampling data to use\n\nSelecting the 0.20% of the data, aiming for around 500K samples for training and testing the model and saving the data in a binary file.\n\n``` r\n## Establishing a connection with the database\ncon <- DBI::dbConnect(duckdb::duckdb(), dbdir = here(\"output/my-db.duckdb\"))\n\n## Defining query to sample\nValidZoneSampleQuery <- glue::glue(\"\nSELECT t1.*\nFROM NycTrips t1\nINNER JOIN ZoneCodesFilter t2\n  ON t1.PULocationID = t2.PULocationID AND\n     t1.DOLocationID = t2.DOLocationID\nUSING SAMPLE 0.20% (system, 547548);\n\")\n\n## Sampling data from db\nValidZoneSample <- DBI::dbGetQuery(con, ValidZoneSampleQuery)\n\n## Closing the database connection\nDBI::dbDisconnect(con, shutdown = TRUE)\n\n## Saving results to disk\nwrite_fst(ValidZoneSample,\n          here(\"output/cache-data/ValidZoneSample.fst\"))\n```\n\n```{r echo=FALSE}\nif(!exists(\"ValidZoneSample\")){\n  ValidZoneSample <- fst::read_fst(\n    here(\"output/cache-data/ValidZoneSample.fst\"),\n    as.data.table = TRUE\n  )\n}\n```\n\n## Adding `take_current_trip` to sample\n\n### Purpose\n\nThe purpose of this variable is to compare each trip with potential trips that a taxi driver could take in the following minutes and determine if it’s better to accept the current trip request or wait for a more profitable trip in the following minutes.\n\n### Assumptions\n\nTo answer this question, we will need assumptions similar to those used in simulating a taxi driver’s decision-making process specially to select the valid trips that need to be taken in consideration to compare with.\n\nFor a trip to be considered valid, it must meet the following requirements:\n\n1.  The trip corresponds to the same company as the original trip request.\n\n2.  Only if the original trip request specified a wheelchair-accessible vehicle (WAV), future WAV trips will be eligible.\n\n3.  The trip was requested from 3 seconds (time needed to reject a trip request) up to 15 minutes after the original request time.\n\n4.  The trip start point is located in valid distance from the start point of the original trip (assuming the taxi driver is in that point) based on the relate time the trip was requested based on the request time of the original trip\n\n    -   0-1 Minute: Only 1-mile radius is valid.\n\n    -   1-3 Minutes: Expand up to 3-mile radius.\n\n    -   3-5 Minutes: Expand up to 5-mile radius.\n\n    -   Keep adding 2 miles until completing the allowed 15 minutes.\n\n### Implementation\n\nSince this process is resource-intensive and each iteration is independent, running it in parallel as a **multicore process** (supported by `future`) is optimal. This approach utilizes the full capacity of my computer, which has 8 cores and 17 GB of RAM.\n\nThe only disadvantage of this approach that my current IDE (Rstudio) don't support this process, but it can be run without issues from the **linux terminal** by writing the process on **Rscript files**.\n\nThe process was implemented in the **`add_take_current_trip()`** which has been **tested** to ensure it meets expectations, as confirmed in the [Github file](https://github.com/AngelFelizR/project.nyc.taxi/blob/master/tests/testthat/test-add_take_current_trip.R).\n\n### Tuning parallel process\n\nBefore running a process 500k times, it's important to make sure we are using the best configuration due the code and the hardware were are using.\n\nIn our case we focus in defining best values for:\n\n-   Number of cores used by `data.table`\n\n-   Number of cores used by `future`\n\n-   Chunk.size used by `future`\n\n-   Scheduling used by `future`\n\nFor that reason we have created the `R/01-fine-tune-future-process.R` script, which print the time needed for each process on the terminal after completing each one.\n\n``` bash\ndocker exec -ti Rstudio bash\ncd home/rstudio/NycTaxi\nRscript R/01-fine-tune-future-process.R\n```\n\nThe below plot summaries the obtained results.\n\n```{r}\n#| echo: false\nBenchmarkResults <- data.frame(\n  CoreConfiguration = c(\n    rep(\"Future: 7 and DT: 1 Cores\", times = 11L),\n    rep(\"Future: 4 and DT: 8 Cores\", times = 12L)\n  ),\n  Scheduling = c(\n    0.4, 0.5, 0.6, 0.4, 0.5, 0.6, 0.4, 0.5, 0.6, 0.4, 0.5,\n    0.4, 0.5, 0.6, 0.4, 0.5, 0.6, 0.4, 0.5, 0.6, 0.4, 0.5, 0.6\n  ),\n  ChunkSize = c(\n    25, 25, 25, 50, 50, 50, 100, 100, 100, 200, 200,\n    5, 25, 25, 50, 50, 50, 100, 100, 100, 200, 200, 200\n  ),\n  Duration = c(\n    528.970, 428.321, 407.558, 382.662, 384.741, 380.178, 379.015, 379.000, 377.592, 373.415, 379.463,\n    538.531, 442.395, 458.97, 424.615, 366.119, 361.745, 350.42, 347.733, 346.434, 351.716, 348.664, 358.177\n  ))\n\nBenchmarkPlot <-\n  ggplot(BenchmarkResults,\n         aes(x = ChunkSize, \n             y = Duration, \n             color = as.character(Scheduling),\n             group = interaction(Scheduling, CoreConfiguration),\n             tooltip = round(Duration,2))) +\n  geom_line() +\n  geom_point_interactive(size = 1.5) +\n  scale_y_log10() +\n  facet_wrap(vars(CoreConfiguration)) +\n  labs(title = \"Future Performance\",\n       color = \"Scheduling\",\n       y = \"Duration (s)\",\n       x = \"Chunk Size\") +\n  theme_minimal() +\n  theme(legend.position = \"top\",\n        plot.title = element_text(face = \"bold\"))\n\ngirafe(ggobj = BenchmarkPlot)\n```\n\nAnd as we can see the got better performance by using fewer cores for future, due the RAM capacity limit, when using only 4 cores and increasing the number of task per core we can see the time needed to complete the 2k samples it's reduced as it didn't use the SWAP memory while running the process, as we can see in the next screenshot.\n\n![](../figures/htop_parallel_process.png)\n\nAnd after checking this results we ended with the next configuration:\n\n-   Number of cores used by `data.table`: 8\n\n-   Number of cores used by `future`: 4\n\n-   Chunk.size used by `future`: 200\n\n-   Scheduling used by `future`: 0.6\n\n### Running process\n\nOnce we know how to set up the parallel process we need to run it month by month and save the results to avoid losing the progress in case of any process fail.\n\nAs this process was very demanding for my computer so we preferred to run each month on individual R session to avoid filling the memory by using the next __bash script__ and passing the each month as param for the __Rscript__.\n\n```{bash}\n#| eval: false\n#| file: ../R/run_add_target.sh\n```\n\nOnce defined the bash script we can use it by running the next command in the terminal.\n\n```bash\ndocker exec -ti Rstudio bash\ncd home/rstudio/NycTaxi\nbash R/run_add_target.sh R/02-add-target.R  1 24\n```\n\nHere we can see that the 24 files have been saved as fst binnary files.\n\n```{bash}\nls -lh ../output/take-trip-fst\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"05-data-sampling.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","editor":"source","theme":"cosmo","title":"Data Sampling","editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}