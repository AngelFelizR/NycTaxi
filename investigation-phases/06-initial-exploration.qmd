---
title: "Initial Exploration"
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

After completing the [business understanding](https://angelfelizr.github.io/NycTaxi/phases/02-business-understanding.html) phase, we are ready to perform the **data understanding** phase by performing an EDA with the following steps:

1.  Exploring the individual distribution of variables.
2.  Exploring correlations between predictors and the target variable.
3.  Exploring correlations between predictors.

This will help to:

-   Ensure data quality.
-   Identify key predictors.
-   Guide model choice and feature engineering.

## Setting up the environment

### Define colors to use

```{r}
ColorHighlight <- "lightslateblue"
ColorGray <- "gray80"
```

### Loading packages

```{r warning = FALSE, message = FALSE}
## To manage relative paths
library(here)

## To import and export data frames as binary files
library(fst)
library(fstcore)

## To transform data that fits in RAM
library(data.table)
library(lubridate)

## To create plots
library(ggplot2)
library(scales)
library(patchwork)
library(DataExplorer)

## Defining the print params to use in the report
options(datatable.print.nrows = 15, digits = 4)
```

### Creating simple functions

In this section we are creating any useful function to run that will be only use during this section and are simple enough to don't need unit test.

It's a simple way to avoid repeating my self as I am exploring the data in this section.

```{r}
#| code-fold: true
#| code-summary: "Show the code"

#' Plot a heatmap of two categorical variables.
#'
#' This function takes a data.table and two categorical variables to create a
#' heatmap visualizing the counts and proportions of their combinations.
#'
#' @param dt A data.table containing the data.
#' @param cat_vars A character vector of length 2 specifying the names of the
#'   two categorical variables in `dt` to be plotted.
#' @param color_high The color to represent high counts in the heatmap.
#' @param color_low The color to represent low counts in the heatmap.
#' @param sep The separator string to use between the proportion (percentage)
#'   and the count in the text labels on the heatmap tiles. Defaults to " | ".
#'
#' @return A ggplot2 object representing the heatmap.
#' 
#' @export
plot_heap_map <- function(dt, 
                          cat_vars,
                          color_high = "lightslateblue",
                          color_low = "gray80",
                          sep = " | ") {
  
  stopifnot("cat_vars most be available in dt" = all(cat_vars %in% names(dt)))
  stopifnot("cat_vars must have 2 variables" = length(cat_vars) == 2L)
  
  dt_summary = dt[, .N, by = cat_vars]
  
  data.table::setnames(dt_summary, cat_vars, c("cat1", "cat2"))
  
  dt_summary[,`:=`(prop  = N / sum(N),
                   cat1 = reorder(cat1, N),
                   cat2 = reorder(cat2, N))] 
  
  
  ggplot2::ggplot(dt_summary, aes(cat1, cat2)) +
    ggplot2::geom_tile(aes(fill = N))+
    ggplot2::geom_text(aes(label = paste0(scales::percent(prop, accuracy = 1),
                                          sep, 
                                          scales::comma(N, accuracy = 1)))) +
    ggplot2::scale_fill_gradient(low = color_low, 
                                 high = color_high,
                                 labels = scales::comma)+
    ggplot2::scale_x_discrete(position = "top")+
    ggplot2::labs(title = cat_vars[2L],
                  x = "",
                  y = "") +
    ggplot2::theme_minimal()+
    ggplot2::theme(panel.grid = element_blank(),
                   plot.title = element_text(face = "bold", size = 15),
                   legend.position = "none") 
  
}


#' Create a bar plot highlighting top categories
#'
#' @description
#' Creates a horizontal bar plot of counts by a categorical variable, highlighting
#' the top n categories with a distinct color.
#'
#' @param dt A data.table object containing the data to be plotted
#' @param var_name Character string specifying the column name in `dt` to use for categorization
#' @param color_highlight Character string specifying the color for the top categories. Default is "lightslateblue"
#' @param color_gray Character string specifying the color for non-top categories. Default is "gray80"
#' @param n_top Integer specifying the number of top categories to highlight. Default is 4
#'
#' @return A ggplot2 object showing the count of trips by category
#'
#' @details
#' The function calculates the count of observations for each unique value in the specified
#' variable, then creates a horizontal bar chart with the top `n_top` categories highlighted
#' in the specified highlight color. All other categories are displayed in the gray color.
#' The bars are sorted in descending order by count.
#'
#'
#' @export

plot_bar <- function(dt,
                     var_name,
                     color_highlight = "lightslateblue",
                     color_gray = "gray80",
                     n_top = 4L){
  
  dt_summary = dt[ 
    j = .(is_top = FALSE,
          n_trips = .N),
    by = var_name
  ]
  
  data.table::setnames(dt_summary, var_name, "cat_summary")
  
  if(n_top > 0L){
    dt_summary[order(-n_trips)[seq_len(n_top)], 
               is_top := TRUE]
  }
 
  
  ggplot2::ggplot(dt_summary,
                aes(n_trips, factor(cat_summary, sort(cat_summary, decreasing = TRUE)))) +
  ggplot2::geom_col(aes(fill = is_top),
                    color = "black",
                    width = 0.8) +
  ggplot2::scale_fill_manual(values = c("TRUE" = color_highlight, 
                                        "FALSE" = color_gray))+
  ggplot2::scale_x_continuous(labels = scales::comma_format()) +
  ggplot2::labs(y = "",
                x = "Number of Trips") +
  ggplot2::theme_minimal() +
  ggplot2::theme(legend.position = "none",
                 panel.grid.major.y = ggplot2::element_blank(),
                 panel.grid.minor.x = ggplot2::element_blank(),
                 plot.title = ggplot2::element_text(face = "bold", size = 15))
  
}

#' Plot Numerical Distribution
#'
#' @description
#' Creates a comprehensive visualization of a numerical variable's distribution with three plots:
#' 1. A standard histogram
#' 2. A logarithmic histogram (excluding zeros)
#' 3. An empirical cumulative distribution function (ECDF) curve
#'
#' @param dt A data.table containing the data
#' @param x Unquoted column name of the numeric variable to plot
#' @param title Character string. Optional title for the combined plots. Default is empty string.
#' @param title_size Numeric. Font size for the title. Default is 15.
#' @param hist_binwidth Numeric. Bin width for the standard histogram. If NULL, ggplot2 chooses automatically.
#' @param hist_n_break Numeric. Number of breaks for x-axis in histograms. If NULL, ggplot2 chooses automatically.
#' @param log_trans Character. Transformation to apply to the logarithmic histogram. Default is "log2".
#'                  Set to NULL for no transformation.
#' @param log_binwidth Numeric. Bin width for the logarithmic histogram. If NULL, ggplot2 chooses automatically.
#' @param curve_important_points Numeric vector. Values to highlight on the ECDF curve with points and percentage labels.
#'                              Default is NULL (no points highlighted).
#' @param curve_nudge_y Numeric. Amount to nudge labels on the ECDF curve in the y direction. Default is 0.
#' @param curve_breaks_x Numeric vector. Custom breaks for x-axis on the ECDF curve. If NULL, ggplot2 chooses automatically.
#' @param curve_limits Numeric vector of length 2 or ggplot2::waiver(). Limits for x-axis on the ECDF curve.
#'                     Default is ggplot2::waiver() (automatic limits).
#'
#' @return A patchwork object combining the three plots vertically
#'
#' @details
#' The function creates a three-panel visualization arranged vertically:
#' - Top panel: Standard histogram of the variable
#' - Middle panel: Logarithmically transformed histogram (zeros are excluded)
#' - Bottom panel: ECDF curve showing the cumulative proportion
#'
#' For the ECDF curve, important points can be highlighted with percentile labels.
#'
plot_num_distribution <- function(dt,
                                  x,
                                  title = "",
                                  title_size = 15,
                                  hist_binwidth = NULL,
                                  hist_n_break = NULL,
                                  log_trans =   scales::new_transform("signed_log2",
                                                                      transform = function(x) sign(x) * log2(1 + abs(x)),
                                                                      inverse = function(x) sign(x) * (2^(abs(x)) - 1),
                                                                      d_transform = function(x) 1 / ((1 + abs(x)) * log(2)),
                                                                      d_inverse = function(x) 2^(abs(x)) * log(2),
                                                                      breaks = scales::pretty_breaks(),
                                                                      domain = c(-Inf, Inf)),
                                  log_binwidth = NULL,
                                  log_breaks = \(x) sign(x) * 2^(-1:10),
                                  curve_important_points = NULL,
                                  curve_nudge_y = 0,
                                  curve_breaks_x = NULL,
                                  curve_limits = NULL){
  
  # Lazy evaluation
  x = rlang::enquo(x)
  x_str <- rlang::quo_name(x)
  
  # Confirming correct format
  stopifnot("dt must be data.table" = data.table::is.data.table(dt))
  
  # Histogram 1 ----------------------------------------------------------------
  
  simple_hist =
    ggplot2::ggplot(dt, ggplot2::aes({{x}})) +
    ggplot2::geom_histogram(binwidth = hist_binwidth) +
    ggplot2::scale_x_continuous(n.breaks = hist_n_break) +
    ggplot2::scale_y_continuous(labels = comma_format()) +
    ggplot2::labs(x = "",
                  y = "Count") +
    ggplot2::theme_minimal()
  
  
  # Log Histogram --------------------------------------------------------------
  
  log_hist =
    ggplot2::ggplot(dt, ggplot2::aes({{x}})) +
    ggplot2::geom_histogram(binwidth = log_binwidth) +
    ggplot2::scale_y_continuous(labels = scales::comma_format()) +
    ggplot2::scale_x_continuous(n.breaks = hist_n_break,
                                transform = log_trans,
                                breaks = log_breaks,
                                labels = \(x) round(x, 2)) +
    ggplot2::labs(x = "",
                  y = "Count") +
    ggplot2::theme_minimal()
  
  
  # ECDF Curve ----------------------------------------------------------------
  
  get_prop = stats::ecdf(dt[[x_str]])
  
  ecdf_plot =
    ggplot2::ggplot(dt, ggplot2::aes({{x}}, get_prop({{x}}))) +
    ggplot2::geom_step()
  
  if(!is.null(curve_important_points)){
    important_df = data.frame(x = curve_important_points)
    names(important_df) = x_str
    
    ecdf_plot =
      ecdf_plot +
      ggplot2::geom_point(data = important_df) +
      ggplot2::geom_text(data = important_df,
                         ggplot2::aes(label = scales::percent(get_prop(!!x), accuracy = 1)),
                         nudge_y = curve_nudge_y)
  }
  
  ecdf_plot =
    ecdf_plot +
    ggplot2::scale_y_continuous(labels = scales::percent_format(),
                                breaks = seq(0, 1, by = 0.25)) +
    ggplot2::scale_x_continuous(labels = scales::comma_format(),
                                breaks = if(is.null(curve_breaks_x)) ggplot2::waiver() else curve_breaks_x,
                                limits = curve_limits) +
    ggplot2::labs(y = "Prop of trips",
                  x = "") +
    ggplot2::theme_minimal()
  
  
  # Consolidating plots using patchwork

  (simple_hist / log_hist / ecdf_plot) +
  patchwork::plot_annotation(title = title) & 
  ggplot2::theme(plot.title = element_text(face = "bold", size = title_size))
  
}

```

```{r}
#| results: 'asis'
#| echo: false

ls() |>
  (\(x) structure(x, names = x))() |>
  sapply(FUN = \(x) class(get(x))) |>
  (\(x) x[x == "function"])() |>
  names() |>
  paste0("- *", a = _, "*") |>
  paste0(collapse = "\n") |>
  cat()
```

### Importing training sample

```{r}
TrainingSample <-
  here("output/take-trip-fst") |>
  list.files(full.names = TRUE) |>
  (\(x) data.table(full_path = x,
                   n_char = nchar(basename(x)),
                   name = basename(x)))() |>
  (\(dt) dt[order(n_char, name), full_path])() |>
  head(12L) |>
  lapply(FUN = read_fst, as.data.table = TRUE) |>
  rbindlist()
```

### Importing geospatial information

```{r}
ZoneCodesRef <-
  fread(here("raw-data/taxi_zone_lookup.csv"),
        select = c("LocationID" = "character",
                   "Borough" = "character",
                   "service_zone" = "character"))
```



### Adding features for exploration

```{r}
TrainingSample[,`:=`(company = fcase(hvfhs_license_num == "HV0002", "Juno",
                                     hvfhs_license_num == "HV0003", "Uber",
                                     hvfhs_license_num == "HV0004", "Via",
                                     hvfhs_license_num == "HV0005", "Lyft"),
                     take_current_trip = fifelse(take_current_trip == 1, "Y", "N"),
                     
                     weekday = wday(request_datetime, label = TRUE, abbr = FALSE, week_start = 1),
                     month = month(request_datetime, label = TRUE, abbr = FALSE),
                     hour = hour(request_datetime),
                     
                     trip_time_min = trip_time / 60,
                     
                     trip_value = tips + base_passenger_fare,
                     
                     PULocationID = as.character(PULocationID),
                     DOLocationID = as.character(DOLocationID))]

# To explore the distribution provided by the `PULocationID` (Pick Up Zone ID) 
# and `DOLocationID` (Drop Off Zone ID), we need to add extra information.
# If we check the taxi zone look up table, we can find the `Borough` and
# `service_zone` of each table.

TrainingSample[ZoneCodesRef,
               on = c("PULocationID" = "LocationID"),
               `:=`(PULocationID = as.character(PULocationID),
                    PUBorough = Borough,
                    PUServiceZone = service_zone)]

TrainingSample[ZoneCodesRef,
               on = c("DOLocationID" = "LocationID"),
               `:=`(DOLocationID = as.character(DOLocationID),
                    DOBorough = Borough,
                    DOServiceZone = service_zone)]
```


## Exploring individual distributions


### Categorical variables

-   Based on `take_current_trip` only 24% of the trips need to be rejected.

-   In `company`, Uber accounts for 72% of trips. In consequence, the results of this project will be **more related to Uber** than any other company.

-   `dispatching_base_num`, `originating_base_num`, and `access_a_ride_flag` all seem to be highly correlated with the company and are **unlikely to be useful for prediction**.

-   Based on `shared_request_flag` and `shared_match_flag` 99% of trips don't request to share the trip and don't end sharing the the trip.

-   Based on `wav_request_flag` and `wav_match_flag` 94% of trips don't request and don't take place in wheelchair-accessible vehicles.

::: panel-tabset

#### Target

```{r}
#| code-fold: true
#| code-summary: "Show the code"

TrainingSample[, .N,
               by = "take_current_trip"
][,`:=`(prop = N / sum(N),
        take_current_trip = reorder(take_current_trip, N))] |>
  ggplot(aes(N, take_current_trip)) +
  geom_col(fill = ColorGray,
           color = "black",
           width = 0.5) +
  geom_text(aes(label = percent(prop, accuracy = 1)),
            nudge_x = 10000) +
  scale_x_continuous(labels = comma_format()) +
  labs(title = "Only 24% of the trips need to be rejected",
       x = "") +
  theme_minimal() +
  theme(panel.grid.major.y = element_blank(),
        panel.grid.minor.x = element_blank(),
        plot.title = element_text(face = "bold", size = 15))
```

#### Company

```{r}
#| code-fold: true
#| code-summary: "Show the code"

TrainingSample[, .N,
               by = "company"
][, prop := N / sum(N)] |>
  ggplot(aes(N, company)) +
  geom_col(fill = ColorGray,
           color = "black",
           width = 0.5) +
  geom_text(aes(label = percent(prop)),
            nudge_x = 6500) +
  scale_x_continuous(labels = comma_format()) +
  labs(title = "Most of the trips come from Uber",
       x = "",
       y = "Company Name") +
  theme_minimal() +
  theme(panel.grid.major.y = element_blank(),
        plot.title = element_text(face = "bold", size = 15))
```

#### Correlated with company

```{r}
#| code-fold: true
#| code-summary: "Show the code"

Plot_dispatching_base_num <-
  plot_heap_map(TrainingSample,
                cat_vars = c("company", "dispatching_base_num"),
                color_high = ColorHighlight,
                color_low = ColorGray)


Plot_originating_base_num <-
  plot_heap_map(TrainingSample,
                cat_vars = c("company", "originating_base_num"),
                color_high = ColorHighlight,
                color_low = ColorGray)

Plot_access_a_ride_flag <-
  plot_heap_map(TrainingSample,
                cat_vars = c("company", "access_a_ride_flag"),
                color_high = ColorHighlight,
                color_low = ColorGray,
                sep = "\n")

Plot_access_a_ride_flag 

(Plot_dispatching_base_num + Plot_originating_base_num)
```


#### Shared trips

```{r}
#| code-fold: true
#| code-summary: "Show the code"

plot_heap_map(TrainingSample,
              cat_vars = c("shared_request_flag", "shared_match_flag"),
              color_high = ColorHighlight,
              color_low = ColorGray,
              sep = "\n") +
  labs(title = "",
       x = "shared_request_flag",
       y = "shared_match_flag")
```

#### Wheelchair-accessible vehicles

```{r}
#| code-fold: true
#| code-summary: "Show the code"


plot_heap_map(TrainingSample,
              cat_vars = c("wav_request_flag", "wav_match_flag"),
              color_high = ColorHighlight,
              color_low = ColorGray,
              sep = "\n") +
  labs(title = "",
       x = "wav_request_flag",
       y = "wav_match_flag")
```

:::


### Datetime variables

Based on the reports, we can confirm that we have a good number of example from each `month`, `weekday` and `hour`. The only exception is December from which only have `r TrainingSample["December", on = "month", nomatch = NULL, comma(.N)]` of the total sample of  `r TrainingSample[, comma(.N)]`.

::: panel-tabset
#### Month

```{r}
#| code-fold: true
#| code-summary: "Show the code"

plot_bar(TrainingSample,
         "month",
         color_highlight = ColorHighlight,
         color_gray = ColorGray)
```

#### Weekday

```{r}
#| code-fold: true
#| code-summary: "Show the code"

plot_bar(TrainingSample,
         "weekday",
         color_highlight = ColorHighlight,
         color_gray = ColorGray,
         n_top = 1L)
```

#### Hour

```{r}
#| code-fold: true
#| code-summary: "Show the code"

plot_bar(TrainingSample,
         "hour",
         color_highlight = ColorHighlight,
         color_gray = ColorGray)
```
:::

### Geospatial data

Based on the next results, we can conclude that:

1.  Based on the `borough`, must of the trips start and end in Manhattan.

2.  `service_zone` is correlated with the `borough` and don't provide much difference information.

3.  We have examples for all `LocationID`, but the number of examples for each zone change a lot from zone to zone, as expected.

::: panel-tabset

#### Borough

```{r}
#| code-fold: true
#| code-summary: "Show the code"

PlotPUBorough <-
  plot_bar(TrainingSample,
           var_name = "PUBorough",
           n_top = 1L) +
  labs(title = "PUBorough")

PlotDOBorough <-
  plot_bar(TrainingSample,
           var_name = "DOBorough",
           n_top = 1L) +
  labs(title = "DOBorough")

PlotPUBorough / PlotDOBorough
```

#### Service Zone

```{r}
#| code-fold: true
#| code-summary: "Show the code"

PlotPUServiceZone <-
  plot_heap_map(TrainingSample,
                cat_vars = c("PUBorough", "PUServiceZone"),
                sep = "\n") +
  labs(title = "PUBorough vs PUServiceZone")

PlotDOServiceZone <-
  plot_heap_map(TrainingSample,
                cat_vars = c("DOBorough", "DOServiceZone"),
                sep = "\n") +
  labs(title = "DOBorough vs DOServiceZone")

PlotPUServiceZone / PlotDOServiceZone
```

#### PU Locations

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#| fig-height: 15

LocationIdTextSize <- 7

setkeyv(TrainingSample, "PUBorough")

PlotPuLocations1 <-
  plot_bar(TrainingSample["Manhattan"],
           var_name = "PULocationID") +
  labs(subtitle = "Manhattan") +
  theme(axis.text.y = element_text(size = LocationIdTextSize))

PlotPuLocations2 <-
  plot_bar(TrainingSample["Brooklyn"],
           var_name = "PULocationID") +
  labs(subtitle = "Brooklyn")+
  theme(axis.text.y = element_text(size = LocationIdTextSize))

PlotPuLocations3 <-
  plot_bar(TrainingSample["Queens"],
           var_name = "PULocationID") +
  labs(subtitle = "Queens")+
  theme(axis.text.y = element_text(size = LocationIdTextSize))

PlotPuLocations1 / PlotPuLocations2 / PlotPuLocations3
```

#### DO Locations

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#| fig-height: 15

setkeyv(TrainingSample, "DOBorough")

PlotDoLocations1 <-
  plot_bar(TrainingSample["Manhattan"],
           var_name = "DOLocationID") +
  labs(subtitle = "Manhattan") +
  theme(axis.text.y = element_text(size = LocationIdTextSize))

PlotDoLocations2 <-
  plot_bar(TrainingSample["Brooklyn"],
           var_name = "DOLocationID") +
  labs(subtitle = "Brooklyn")+
  theme(axis.text.y = element_text(size = LocationIdTextSize))

PlotDoLocations3 <-
  plot_bar(TrainingSample["Queens"],
           var_name = "DOLocationID") +
  labs(subtitle = "Queens")+
  theme(axis.text.y = element_text(size = LocationIdTextSize))

PlotDoLocations1 / PlotDoLocations2 / PlotDoLocations3
```

:::

### Numerical variables

Based on the below graphs, we can say that:

1. `trip_miles`

::: panel-tabset

#### Trip miles

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#| fig-height: 10

plot_num_distribution(TrainingSample,
                      trip_miles,
                      title = "trip_miles",
                      hist_binwidth = 5,
                      hist_n_break = 12,
                      log_binwidth = 0.5,
                      curve_important_points = c(1, 6, 24),
                      curve_limits = c(0, 25),
                      curve_nudge_y = 0.08,
                      curve_breaks_x = breaks_width(3))

```

#### Trip time

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#| fig-height: 10

plot_num_distribution(TrainingSample,
                      trip_time_min,
                      title = "trip_time_min",
                      hist_binwidth = 5,
                      hist_n_break = 15,
                      log_binwidth = 0.5,
                      curve_important_points = c(4, 25, 60),
                      curve_nudge_y = 0.1,
                      curve_breaks_x = scales::breaks_width(10),
                      curve_limits = c(0, 70))

```

#### tips + base_passenger_fare

```{r}
#| code-fold: true
#| code-summary: "Show the code"

plot_num_distribution(TrainingSample,
                      trip_value,
                      title = "trip_value",
                      hist_n_break = 12,
                      curve_limits = c(0, 100))
```

#### performance_per_hour

```{r}
#| code-fold: true
#| code-summary: "Show the code"

TripPerformancePlot <-
  ggplot(TrainingSample) +
  stat_ecdf(aes(performance_per_hour)) +
  scale_y_continuous(labels = percent_format()) +
  scale_x_continuous(labels = comma_format(),
                     breaks = breaks_width(3000)) +
  labs(subtitle = "All points of training set",
       x = "") +
  theme_minimal()


TripPerformanceRangePlot <-
  ggplot(TrainingSample[trip_time >= 60*5 & base_passenger_fare > 0]) +
  stat_ecdf(aes(performance_per_hour)) +
  scale_x_continuous(labels = comma_format(),
                     n.breaks = 12) +
  scale_y_continuous(labels = percent_format(),
                     n.breaks = 5) +
  labs(subtitle = "Trips with 5 min and positive base fare",
       x = "") +
  theme_minimal()

(TripPerformancePlot / TripPerformanceRangePlot) +
  plot_annotation(title = 'Cumulative distribution of trip performance') & 
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(face = "bold", size = 15),
        plot.subtitle = element_text(size = 13, face = "italic"))

```
:::


### Conclusions

After all that exploration, we need to apply the following changes to keep exploring:

- We don't want to focus on trips that took less than 4 minutes to avoid the __small denominator distortion__ in the `performance_per_hour` metric.
- The `base_passenger_fare` and the `performance_per_hour` must be positive.
- Based on the prior exploration, we now that we cannot use the `access_a_ride_flag`, `originating_base_num`, and `dispatching_base_num` for modeling.
- To help the model differentiate between location IDs, let's count the number of trips we see in the training set.
- As `PULocationID` and `DOLocationID` have many levels, we only need the top 29 for visualization. The remaining levels will be shown as "Other".
- To understand better the relations between the target variables and the `request_datetime`, we are going to break it down by month, every other week, weekday, and hour.

```{r}
TrainingSampleToExplore <-
  TrainingSampleZones[trip_time >= 60*4 & 
                        base_passenger_fare > 0 &
                        performance_per_hour > 0, 
                      .SD, 
                      .SDcols = patterns("^(PU|DO)|license|shared|wav|request_datetime|trip_miles|performance_per_hour|take_current_trip")
  ][, PULocation_annual_trips := .N,
    by = "PULocationID"
  ][, DOLocation_annual_trips := .N,
    by = "DOLocationID"
  ][, `:=`(PULocationID = forcats::fct_lump_n(as.character(PULocationID), 29),
           DOLocationID = forcats::fct_lump_n(as.character(DOLocationID), 29),
           request_datetime = NULL,
           month = month(request_datetime, label = TRUE, abbr = FALSE),
           bi_week = floor((week(request_datetime) + 1) / 2) |> (\(x) factor(x, sort(unique(x))) )(),
           weekday = wday(request_datetime, label = TRUE, abbr = FALSE, week_start = 1),
           hour = hour(request_datetime) |> (\(x) factor(x, sort(unique(x))) )())]
```


## Predictors vs `take_current_trip`

As we can see below, the proportion of trips to take changes for the next features:

- Location ID
- Borough
- Service zone
- shared_request_flag
- shared_match_flag
- wav_request_flag
- wav_match_flag

But we cannot see important fluctuations for:

- weekday
- month
- hour

In the case of `trip_miles`, both groups present similar distributions, but we can see that if the trip has more than 50 miles it's always a good choice to take it.

::: panel-tabset

### Categorical

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#| eval: false

DataExplorer::plot_bar(TrainingSampleToExplore,
                       by = "take_current_trip",
                       nrow = 2,
                       ggtheme = theme_minimal(),
                       theme_config = list(legend.position = "top",
                                           panel.grid = element_blank()))
```

### Numerical

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#| fig-height: 10
#| fig-width: 8

TrainingSampleNumericLong <-
  TrainingSampleToExplore[j = melt(.SD, id.vars = c("performance_per_hour", "take_current_trip")), 
                          .SDcols = patterns("annual_trips|trip_miles|performance_per_hour|take_current_trip")]

ggplot(TrainingSampleNumericLong,
       aes(take_current_trip, value)) +
  geom_boxplot() +
  scale_y_continuous(n.breaks = 10) +
  facet_wrap(vars(variable),
             scales = "free",
             ncol = 1) +
  theme_minimal() +
  theme(legend.position = "top",
        panel.grid.major.x = element_blank())
```

:::

##  Predictors vs `performance_per_hour`

As we can see in the below charts, __categorical predictors don't seem to provide a very impactful variable__ for modeling at a first glance, as the distribution of `performance_per_hour` is very similar in multiple categories.

If we focus on the `trip_miles` predictor, we can see how:

- Trips with less than 30 miles present high variation, with very high-paid trips and very low-value trips, but most of the trips present low value.
- There is not a linear relationship between the `trip_miles` variable and `performance_per_hour`.
- On average, the `performance_per_hour` increases with miles, especially for trips with more than 30 miles.
- We don't see any clear relation between `performance_per_hour` and the number of trips for each zone.

It would be really interesting if the model could identify which trips have a `performance_per_hour >= 100`; **that would be more useful to model**.

::: panel-tabset

### Categorical

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#| fig-height: 23
#| fig-width: 10

TrainingSampleToExplore[j = melt(.SD, id.vars = "performance_per_hour"), 
                        .SDcols = !patterns("annual_trips|trip_miles")] |>
  ggplot(aes(value, performance_per_hour)) +
  geom_violin() +
  scale_y_continuous(transform = "log2",
                     n.breaks = 5) +
  facet_wrap(vars(variable),
             scales = "free",
             ncol = 2) +
  theme_minimal() +
  theme(legend.position = "top",
        panel.grid.major.x = element_blank())
```

### Numerical

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#| fig-height: 10
#| fig-width: 8

ggplot(TrainingSampleNumericLong,
       aes(value, performance_per_hour))+
  geom_point(alpha = 0.1) +
  geom_smooth(method = "lm") +
  scale_x_continuous(n.breaks = 15) +
  scale_y_continuous(n.breaks = 10) +
  facet_wrap(vars(variable),
             ncol = 1L,
             scales = "free") +
  theme_minimal()
```

:::

## Predictors vs `performance_per_hour >= 100`

After focusing on identifying high-value trips, most of the **categorical predictors reveal more information that could be useful for making predictions**. The distributions of high-value and not-high-value trips show noticeable differences across several categories, although these differences are much more pronounced in some categories than in others. The `wav_match_flag` stands out as an exception with virtually identical distributions for both groups.

High-value trips are typically associated with __short distances__ and locations with __many trips__ per year.

::: panel-tabset

### Categorical

```{r}
#| code-fold: true
#| code-summary: "Show the code"

copy(TrainingSampleToExplore)[, high_value_trip := fifelse(performance_per_hour >= 100, "Y", "N") ]|>
  DataExplorer::plot_bar(by = "high_value_trip",
                         nrow = 2,
                         ggtheme = theme_minimal(),
                         theme_config = list(legend.position = "top",
                                             panel.grid = element_blank()))
```

### Numerical

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#| fig-height: 10
#| fig-width: 8

TrainingSampleNumericLong |>
  ggplot(aes(fifelse(performance_per_hour >= 100, "Y", "N"), value)) +
  geom_boxplot() +
  scale_y_continuous(n.breaks = 10) +
  facet_wrap(vars(variable),
             ncol = 1L,
             scales = "free") +
  theme_minimal() +
  theme(legend.position = "top",
        panel.grid.major.x = element_blank())
```

:::

## Exploring correlations between predictors

`month` and `bi_week` show a 94% correlation, suggesting significant overlap (e.g., biweekly periods may map directly to months). Including both in a model could introduce multicollinearity.

Location-based features like PULocationID ↔ PUBorough (83%) and DOLocationID ↔ DOServiceZone (84%) are strongly associated, as location IDs inherently determine boroughs/zones.

```{r}
#| code-fold: true
#| code-summary: "Show the code"

copy(TrainingSampleToExplore)[, trip_miles := cut_interval(trip_miles, 8)] |>
  corrcat::cramerV_df(unique = FALSE)|>
  ggplot(aes(V1, V2, fill = `Cramer.V`))+
  geom_tile()+
  scale_fill_gradient(low = "white",
                      high = ColorHighlight,
                      space = "Lab",
                      na.value = "white") +
  geom_text(aes(label = percent(`Cramer.V`, accuracy = 1)),
            size = 2.5) + 
  labs(title = "Cramer's V correlation")+
  theme_minimal()+
  theme(legend.position = "none",
        panel.grid = element_blank(),
        axis.text.x = element_text(angle = 90),
        axis.title = element_blank())
```

## Exploring correlation funnel

Based on the below correlation funnels, we can confirm that no predictor has a strong correlation with the target variables, so we know that linear models won't perform well with this data.

::: panel-tabset

### take_current_trip

```{r}
TrainingSampleToExplore[, -c("performance_per_hour")] |>
  correlationfunnel::binarize()  |>
  correlationfunnel::correlate(take_current_trip__Y) |>
  correlationfunnel::plot_correlation_funnel()
```

### performance_per_hour >= 100

```{r}
copy(TrainingSampleToExplore)[, `:=`(take_current_trip = NULL,
                                     performance_per_hour = NULL,
                                     high_value_trip = performance_per_hour >= 100)] |>
  correlationfunnel::binarize()  |>
  correlationfunnel::correlate(high_value_trip__1) |>
  correlationfunnel::plot_correlation_funnel()
```

:::

## Final conclusion

This EDA revealed key patterns and challenges for our NYC taxi trip prediction models:

**Key Findings:**

*   **Data Filtering:** We'll filter out trips under 4 minutes and with zero or negative base fares.
*   **Uber Dominance:** Uber trips constitute 72% of the data, so model results will be more related to this company.
*   **Temporal Features:** Strong hourly, daily, bi-weekly, and monthly trends exist, requiring time-based features (weekday, month, hour, sin/cos transformations).
*   **Geospatial Relevance:**  Location IDs, boroughs, and service zones impact trip selection, but are highly correlated; we'll select one per correlated group of features to avoid multicollinearity.
*   **Target Insights:**
    *   `take_current_trip` shows variations based on location, trip type, shared and WAV flags, but not so much on time variables.
    *   `performance_per_hour` does not show a clear relation with categorical variables, while, high-value trips (`performance_per_hour >= 100`) do show differences on their distributions.
    *   No strong linear correlations were found, so we will not start with linear models.

**Modeling Implications:**

*   **Non-Linear Models:** Linear models will not be useful, so we will prioritize non-linear models such as tree-based methods or stacked models.
*   **Feature Engineering:**  We will create time and location-related features. We will use  the count of trips on each location and the `shared` and `wav` flags, and focus on predicting `performance_per_hour >= 100`.
*   **Class Imbalance:** The target `take_current_trip` has a class imbalance, which should be addressed with oversampling.
*   **Multicollinearity:** Highly correlated features must be removed (e.g., `month` or `bi_week`, `borough` or `service_zone`).
