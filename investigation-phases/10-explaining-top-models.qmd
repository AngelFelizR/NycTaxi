---
title: "Expaling Top Models"
editor_options: 
  chunk_output_type: console
execute:
  message: false
  warning: false
---

Now is time to understand what is going under the h
    
## Setting up the environment

Here are the loaded libraries to start the process.

```{r}
## To manage relative paths
library(here)

## To transform data that fits in RAM
library(data.table)
library(lubridate)
library(timeDate)
library(ggtext)

## Tools for modeling
library(tidymodels)
library(embed)
library(themis)
library(discrim)


## Publish data sets, models, and other R objects
library(pins)

## Custom functions
devtools::load_all()

# Defining the pin boards to use
BoardLocal <- board_folder(here("../NycTaxiPins/Board"))

# Loading params
Params <- yaml::read_yaml(here("params.yml"))
Params$BoroughColors <- unlist(Params$BoroughColors)
```

## Importing training data

Here we import the data to use from the remote Board located in a github repo.

```{r}
AcsVariablesByZoneId <- pin_read(BoardLocal, "AcsVariablesByZoneId")[,
  LocationID := as.character(LocationID)
]

OmsDensityFeatures <- pin_read(BoardLocal, "OmsDensityFeatures")[,
  LocationID := as.character(LocationID)
]

ZoneCodesRef <- pin_read(BoardLocal, "ZoneCodesRef")[, c(
  "LocationID",
  "Borough",
  "service_zone"
)]

SampledData <-
  pin_list(BoardLocal) |>
  grep(pattern = "^OneMonthData", value = TRUE) |>
  sort() |>
  head(12L) |>
  lapply(FUN = pin_read, board = BoardLocal) |>
  rbindlist() |>
  tibble::as_tibble() |>
  mutate(
    take_current_trip = fifelse(take_current_trip == 1L, "yes", "no") |>
      factor(levels = c("yes", "no")),
    PULocationID = as.character(PULocationID),
    DOLocationID = as.character(DOLocationID)
  )

set.seed(2545)
TrainingSample <-
  initial_split(SampledData, strata = take_current_trip) |>
  training()
```

## Defining data to explain

```{r}
set.seed(2971)
ExplainSplit <- initial_split(TrainingSample, strata = take_current_trip)

ExplainTraining <- training(ExplainSplit)
ExplainTesting <- testing(ExplainSplit)
```

## Importing workflows

```{r}
WorkflowsToImport <-
  pin_list(BoardLocal) |>
  grep(pattern = "^InitialFinalized\\w+Wf$", value = TRUE)

names(WorkflowsToImport) <-
  WorkflowsToImport |>
  sub(pattern = "^InitialFinalized", replacement = "") |>
  sub(pattern = "Wf$", replacement = "")

InitialFinalizedWf <- lapply(
  WorkflowsToImport,
  FUN = pin_read,
  board = BoardLocal
)

InitialFinalizedWf <- as_workflow_set(!!!InitialFinalizedWf)

InitialFinalizedWf
```

## Fitting workflows

```{r}
#| eval: false

InitialFittedWf <-
  InitialFinalizedWf |>
  mutate(fit = map(info, ~ fit(.x$workflow[[1L]], ExplainTraining)))

pin_write(
  BoardLocal,
  InitialFittedWf,
  name = "InitialFittedWf",
  type = "qs2",
  title = "Initial Fitted Wf"
)
```

```{r}
InitialFittedWf <- pin_read(
  BoardLocal,
  name = "InitialFittedWf"
)
```


## Getting residuals for all models

```{r}
#| eval: false

ExplainTestingOutputCols <-
  ExplainTesting |>
  select(
    trip_id,
    performance_per_hour,
    percentile_75_performance,
    take_current_trip
  )

ExplainTestingPredictions <-
  InitialFittedWf |>
  transmute(
    wflow_id,
    .predictions = map(
      fit,
      ~ bind_cols(
        ExplainTestingOutputCols,
        predict(.x, new_data = ExplainTesting, type = "class"),
        predict(.x, new_data = ExplainTesting, type = "prob")
      )
    )
  ) |>
  unnest(.predictions)

pin_write(
  BoardLocal,
  ExplainTestingPredictions,
  name = "ExplainTestingPredictions",
  type = "qs2",
  title = "Explain Testing Predictions"
)
```

```{r}
ExplainTestingPredictions <- pin_read(
  BoardLocal,
  name = "ExplainTestingPredictions"
)
```


## Model Cost

```{r}
add_error_cost <- function(dt) {
  mutate(
    dt,
    current_method_cost = if_else(
      take_current_trip == "no",
      percentile_75_performance - performance_per_hour,
      0
    ),
    cost_wrong_no = if_else(
      take_current_trip != .pred_class & .pred_class == "no",
      performance_per_hour - percentile_75_performance,
      0
    ),
    cost_wrong_yes = if_else(
      take_current_trip != .pred_class & .pred_class == "yes",
      percentile_75_performance - performance_per_hour,
      0
    ),
    cost_wrong_total = cost_wrong_no + cost_wrong_yes
  )
}


calculate_cost_by_threshold <- function(threshold) {
  ExplainTestingPredictions |>
    mutate(
      threshold = threshold,
      .pred_class = if_else(.pred_yes >= threshold, "yes", "no")
    ) |>
    add_error_cost() |>
    group_by(wflow_id, threshold) |>
    summarize(
      current_method_cost = sum(current_method_cost),
      cost_wrong_total = sum(cost_wrong_total, na.rm = TRUE)
    )
}

lapply(seq(0, 0.5, by = 0.05), FUN = calculate_cost_by_threshold) |>
  bind_rows() |>
  pivot_longer(
    cols = !c(threshold, wflow_id),
    names_to = "cost_source",
    values_to = "cost"
  ) |>
  ggplot(aes(threshold, cost, color = cost_source, group = cost_source)) +
  geom_line() +
  geom_point() +
  scale_y_continuous(
    labels = scales::label_currency(accuracy = 1, scale = 1e-3, suffix = "k")
  ) +
  expand_limits(y = 0) +
  facet_wrap(vars(wflow_id)) +
  theme_minimal() +
  theme(legend.position = "top")
```


## 

```{r}
ExplainTestingNoPredictions <-
  ExplainTestingPredictions |>
  filter(take_current_trip == "no") |>
  add_error_cost() |>
  group_by(trip_id) |>
  summarize(
    cost_wrong_total = sum(cost_wrong_total),
    models_correct = sum(take_current_trip == .pred_class)
  )

ExplainTestingNoPredictions |>
  mutate(models_correct = factor(models_correct)) |>
  group_by(models_correct) |>
  mutate(
    models_correct = forcats::fct_relabel(
      models_correct,
      ~ paste0("n=", scales::comma(n()), "\n", .x)
    )
  ) |>
  ggplot() +
  geom_col(aes(models_correct, cost_wrong_total)) +
  scale_y_continuous(
    labels = scales::label_currency(accuracy = 1, scale = 1e-3, suffix = "k")
  ) +
  theme_minimal()
```

```{r}
ExplainTestingPredictions |>
  semi_join(
    filter(ExplainTestingNoPredictions, models_correct == 0L),
    by = "trip_id"
  ) |>
  add_error_cost() |>
  pivot_wider(
    id_cols = c(
      trip_id,
      performance_per_hour,
      percentile_75_performance,
      cost_wrong_total
    ),
    names_from = wflow_id,
    values_from = .pred_yes
  ) |>
  arrange(desc(cost_wrong_total))
```

```{r}
ExplainTestingPredictions |>
  filter(take_current_trip == "no") |>
  group_by(trip_id) |>
  mutate(models_correct = sum(take_current_trip == .pred_class)) |>
  ungroup() |>
  filter(models_correct == 0L) |>
  arrange(trip_id)
```



```{r}
library(DALEX)
fitted_resamples = InitialFinalizedLogisticFitted
fold_id = "Fold1"
create_fold_explainer <- function(fitted_resamples, fold_id) {
  order_id = sub("Fold", "", fold_id) |> as.integer()
  fitted_workflow = fitted_resamples$.extracts[[order_id]]$`.extracts`[[1L]]
  testing_data = testing(fitted_resamples$splits[[order_id]])

  DALEXtra::explain_tidymodels(
    fitted_workflow,
    data = testing_data,
    y = as.double(testing_data[["take_current_trip"]] == "yes")
  )
}

CreatedFold <- InitialFinalizedLogisticFitted$id
names(CreatedFold) <- CreatedFold

ExplainerList <- lapply(
  CreatedFold,
  FUN = create_fold_explainer,
  fitted_resamples = InitialFinalizedLogisticFitted
)

set.seed(1801)
biggest_error <-
  predict_parts(
    explainer = ExplainerList[["Fold1"]],
    new_observation = TrainingSample[40800, ]
  )
```

```{r}
library(forcats)
biggest_error %>%
  group_by(variable) %>%
  mutate(mean_val = mean(contribution)) %>%
  ungroup() %>%
  mutate(variable = fct_reorder(variable, abs(mean_val))) %>%
  ggplot(aes(contribution, variable, fill = mean_val > 0)) +
  geom_col(
    data = ~ distinct(., variable, mean_val),
    aes(mean_val, variable),
    alpha = 0.5
  ) +
  geom_boxplot(width = 0.5) +
  theme(legend.position = "none") +
  scale_fill_viridis_d() +
  labs(y = NULL)
```

