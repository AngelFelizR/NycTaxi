---
title: "Training Initial Models"
editor_options: 
  chunk_output_type: console
execute:
  message: false
  warning: false
---

After exploring the data and getting new features it's time to explore the data using ML models to extract insights that will be used to create the final model.

In this section we will start defining the models to train. We trained a diverse set of models, from simple, interpretable ones (Logistic Regression) to complex, powerful ones (Random Forests), to see which approach works best for our data and hardware constraints:

- Regularized Regression Logistic Regression via glmnet
- Flexible discriminant analysis
- MARS via earth
- Bagged trees via rpart
- Random forests via ranger
- Boosted trees via xgboost

We are going to fit 5 random variations of the different parameters to tune over 5 fold cross validation, then explore the results of each model.
    
## Setting up the environment

Here are the loaded libraries to start the process.

```{r}
## To manage relative paths
library(here)

## To transform data that fits in RAM
library(data.table)
library(lubridate)
library(timeDate)
library(ggtext)

## Tools for modeling
library(tidymodels)
library(embed)
library(themis)
library(discrim)
library(baguette)

## Publish data sets, models, and other R objects
library(pins)

## Custom functions
devtools::load_all()

# Defining the pin boards to use
BoardLocal <- board_folder(here("../NycTaxiPins/Board"))

# Loading params
Params <- yaml::read_yaml(here("params.yml"))
Params$BoroughColors <- unlist(Params$BoroughColors)
```


## Defining models to train

Now we can define the models to be trained and tuned.

```{r}
# Regularized regression logistic regression
GlmnetSpec <-
  logistic_reg(penalty = tune(), mixture = tune()) |>
  set_mode("classification") |>
  set_engine("glmnet")

# Flexible discriminant analysis
FdaSpec <-
  discrim_flexible(prod_degree = tune()) |>
  set_mode("classification") |>
  set_engine('earth')

# MARS
EarthSpec <-
  mars(num_terms = tune(), prod_degree = tune()) |>
  set_mode("classification")

# Bagged trees
C5BagSpec <-
  bag_tree(min_n = tune()) |>
  set_mode("classification") |>
  set_engine("C5.0")

# Random forests
RangerSpec <-
  rand_forest(mtry = tune(), min_n = tune(), trees = 250) |>
  set_mode("classification") |>
  set_engine("ranger")

# Boosted trees
XgboostSpec <-
  boost_tree(
    trees = 250,
    min_n = tune(),
    tree_depth = tune(),
    learn_rate = tune(),
    loss_reduction = tune(),
    sample_size = tune()
  ) |>
  set_mode("classification") |>
  set_engine("xgboost")
```

## Importing data

Here we import the data to use from the remote Board located in a github repo.

```{r}
#| eval: false

AcsVariablesByZoneId <-
  pin_read(BoardLocal, "AcsVariablesByZoneId")[,
    LocationID := as.character(LocationID)
  ]

OmsDensityFeatures <- pin_read(BoardLocal, "OmsDensityFeatures")[,
  LocationID := as.character(LocationID)
]

ZoneCodesRef <- pin_read(BoardLocal, "ZoneCodesRef")[, c(
  "LocationID",
  "Borough",
  "service_zone"
)]

SampledData <-
  pin_list(BoardLocal) |>
  grep(pattern = "^OneMonthData", value = TRUE) |>
  sort() |>
  head(12L) |>
  lapply(FUN = pin_read, board = BoardLocal) |>
  rbindlist() |>
  tibble::as_tibble() |>
  mutate(
    take_current_trip = fifelse(take_current_trip == 1L, "yes", "no") |>
      factor(levels = c("yes", "no")),
    PULocationID = as.character(PULocationID),
    DOLocationID = as.character(DOLocationID)
  )

set.seed(2545)
SampledDataSplit <- initial_split(SampledData, strata = take_current_trip)

TrainingSample <- training(SampledDataSplit)
TestingSample <- testing(SampledDataSplit)
```

## Creating consolidation recipe

As we want to create a final recipe that can reproduce the whole pipeline we start creating a recipe that combine all features that can be used to train the model, so we we run `predict` we would only need to provide the basic data from the original source of [TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page) and all the rest of feature would be added as part of the tidymodels workflow. 

```{r}
#| eval: false

ConsolidationRecipe <-
  # Starting Recipe
  recipe(
    take_current_trip ~
      PULocationID +
      DOLocationID +
      wav_match_flag +
      hvfhs_license_num +
      trip_miles +
      trip_time +
      driver_pay +
      request_datetime +
      trip_id +
      performance_per_hour +
      percentile_75_performance,
    data = TrainingSample
  ) |>

  # Updating roles of variables important for trip identification
  update_role(
    trip_id,
    performance_per_hour,
    percentile_75_performance,
    new_role = "additional info"
  ) |>

  # Selecting variables over 2 min
  step_filter(trip_time >= (60 * 2)) |>

  # Renaming variables to join
  step_rename(PU_LocationID = PULocationID, DO_LocationID = DOLocationID) |>

  # Adding Geospatial Data
  step_join_geospatial_features(
    ends_with("LocationID"),
    spatial_features = ZoneCodesRef,
    col_prefix = c("DO_", "PU_")
  ) |>
  step_join_geospatial_features(
    ends_with("LocationID"),
    spatial_features = AcsVariablesByZoneId,
    col_prefix = c("DO_", "PU_")
  ) |>
  step_join_geospatial_features(
    ends_with("LocationID"),
    spatial_features = OmsDensityFeatures,
    col_prefix = c("DO_", "PU_")
  ) |>

  # Transforming strings to factors
  step_string2factor(all_string_predictors()) |>

  # Daily cycle
  step_harmonic(
    request_datetime,
    frequency = 1,
    cycle_size = 3600 * 24,
    keep_original_cols = TRUE
  ) |>
  step_rename(
    request_datetime_sin_daily = request_datetime_sin_1,
    request_datetime_cos_daily = request_datetime_cos_1
  ) |>

  # Weekly cycle
  step_harmonic(
    request_datetime,
    frequency = 1,
    cycle_size = 3600 * 24 * 7,
    keep_original_cols = TRUE
  ) |>
  step_rename(
    request_datetime_sin_weekly = request_datetime_sin_1,
    request_datetime_cos_weekly = request_datetime_cos_1
  ) |>

  # Extracting additional information
  step_date(
    request_datetime,
    features = c(
      "year",
      "week",
      "decimal",
      "semester",
      "quarter",
      "doy",
      "dow",
      "mday",
      "month"
    )
  ) |>

  step_holiday(
    request_datetime,
    holidays = c(
      'USChristmasDay',
      'USColumbusDay',
      'USCPulaskisBirthday',
      'USDecorationMemorialDay',
      'USElectionDay',
      'USGoodFriday',
      'USInaugurationDay',
      'USIndependenceDay',
      'USJuneteenthNationalIndependenceDay',
      'USLaborDay',
      'USLincolnsBirthday',
      'USMemorialDay',
      'USMLKingsBirthday',
      'USNewYearsDay',
      'USPresidentsDay',
      'USThanksgivingDay',
      'USVeteransDay',
      'USWashingtonsBirthday'
    )
  ) |>

  step_mutate(
    .pkgs = c("data.table", "lubridate", "timeDate"),

    company = fcase(
      hvfhs_license_num == "HV0002" ,
      "Juno"                        ,
      hvfhs_license_num == "HV0003" ,
      "Uber"                        ,
      hvfhs_license_num == "HV0004" ,
      "Via"                         ,
      hvfhs_license_num == "HV0005" ,
      "Lyft"                        ,
      default = "New"
    ) |>
      as.factor(),

    request_datetime_am = am(request_datetime) |> as.integer(),
    request_datetime_pm = pm(request_datetime) |> as.integer(),

    `Days to USChristmasDay` = difftime(
      USChristmasDay(year(request_datetime)),
      request_datetime,
      units = 'days'
    ) |>
      as.integer(),
    `Days to USColumbusDay` = difftime(
      USColumbusDay(year(request_datetime)),
      request_datetime,
      units = 'days'
    ) |>
      as.integer(),
    `Days to USCPulaskisBirthday` = difftime(
      USCPulaskisBirthday(year(request_datetime)),
      request_datetime,
      units = 'days'
    ) |>
      as.integer(),
    `Days to USDecorationMemorialDay` = difftime(
      USDecorationMemorialDay(year(request_datetime)),
      request_datetime,
      units = 'days'
    ) |>
      as.integer(),
    `Days to USElectionDay` = difftime(
      USElectionDay(year(request_datetime)),
      request_datetime,
      units = 'days'
    ) |>
      as.integer(),
    `Days to USGoodFriday` = difftime(
      USGoodFriday(year(request_datetime)),
      request_datetime,
      units = 'days'
    ) |>
      as.integer(),
    `Days to USInaugurationDay` = difftime(
      USInaugurationDay(year(request_datetime)),
      request_datetime,
      units = 'days'
    ) |>
      as.integer(),
    `Days to USIndependenceDay` = difftime(
      USIndependenceDay(year(request_datetime)),
      request_datetime,
      units = 'days'
    ) |>
      as.integer(),
    `Days to USJuneteenthNationalIndependenceDay` = difftime(
      USJuneteenthNationalIndependenceDay(year(request_datetime)),
      request_datetime,
      units = 'days'
    ) |>
      as.integer(),
    `Days to USLaborDay` = difftime(
      USLaborDay(year(request_datetime)),
      request_datetime,
      units = 'days'
    ) |>
      as.integer(),
    `Days to USLincolnsBirthday` = difftime(
      USLincolnsBirthday(year(request_datetime)),
      request_datetime,
      units = 'days'
    ) |>
      as.integer(),
    `Days to USMemorialDay` = difftime(
      USMemorialDay(year(request_datetime)),
      request_datetime,
      units = 'days'
    ) |>
      as.integer(),
    `Days to USMLKingsBirthday` = difftime(
      USMLKingsBirthday(year(request_datetime)),
      request_datetime,
      units = 'days'
    ) |>
      as.integer(),
    `Days to USNewYearsDay` = difftime(
      USNewYearsDay(year(request_datetime)),
      request_datetime,
      units = 'days'
    ) |>
      as.integer(),
    `Days to USPresidentsDay` = difftime(
      USPresidentsDay(year(request_datetime)),
      request_datetime,
      units = 'days'
    ) |>
      as.integer(),
    `Days to USThanksgivingDay` = difftime(
      USThanksgivingDay(year(request_datetime)),
      request_datetime,
      units = 'days'
    ) |>
      as.integer(),
    `Days to USVeteransDay` = difftime(
      USVeteransDay(year(request_datetime)),
      request_datetime,
      units = 'days'
    ) |>
      as.integer(),
    `Days to USWashingtonsBirthday` = difftime(
      USWashingtonsBirthday(year(request_datetime)),
      request_datetime,
      units = 'days'
    ) |>
      as.integer()
  ) |>

  # Removing variables
  step_rm(ends_with(c(
    "LocationID",
    "request_datetime",
    "hvfhs_license_num"
  ))) |>

  # Balancing data
  step_downsample(take_current_trip, under_ratio = 1)
```

## Consolidating features

As we are planing to train many models it's better to apply this initial recipes to the training and testing data to avoid having to apply the the same steps for each resample to train.

```{r}
#| eval: false

TrainingSampleJoined <-
  prep(ConsolidationRecipe) |>
  bake(new_data = NULL)

pin_write(
  BoardLocal,
  TrainingSampleJoined,
  "TrainingSampleJoined",
  type = "qs2",
  title = "Training Sample Joined"
)

```

```{r}
#| echo: false
#| output: false

TrainingSampleJoined <- pin_read(BoardLocal, "TrainingSampleJoined")
```

## Common steps for all recipes

Before creating the the first recipe it's  important to take in consideration that we want to keep `performance_per_hour` and `percentile_75_performance` to see how much money we could be losing for bad predictions.

```{r}
start_recipe <- function(df) {
  new_recipe =
    recipe(take_current_trip ~ ., data = df) |>
    step_impute_median(all_numeric_predictors()) |>
    update_role(
      trip_id,
      performance_per_hour,
      percentile_75_performance,
      new_role = "additional info"
    )

  return(new_recipe)
}
```

## Defining recipes for models that need normalized data

As the models that will be trained based on this data are very affect by class imbalance will downsample to avoid those problems and speed the training time, take in consideration that we have many examples of both cases and are looking for general rules that could used by taxi drivers. 

```{r}
BasicNormalizedRecipe <-
  start_recipe(TrainingSampleJoined) |>
  step_YeoJohnson(all_numeric_predictors()) |>
  step_novel(all_nominal_predictors()) |>
  step_dummy(all_nominal_predictors()) |>
  step_nzv(all_predictors()) |>
  step_normalize(all_numeric_predictors())

NormalizedPcaRecipe <-
  BasicNormalizedRecipe |>
  step_pca(all_numeric_predictors(), num_comp = tune()) |>
  step_normalize(all_numeric_predictors())

NormalizedPlsRecipe <-
  BasicNormalizedRecipe |>
  step_pls(
    all_numeric_predictors(),
    outcome = "take_current_trip",
    num_comp = tune()
  ) |>
  step_normalize(all_numeric_predictors())

NormalizedUmapRecipe <-
  BasicNormalizedRecipe |>
  step_umap(
    all_numeric_predictors(),
    outcome = "take_current_trip",
    neighbors = tune(),
    num_comp = tune()
  ) |>
  step_normalize(all_numeric_predictors())
```

## Defining recipes for tree based models

```{r}

ReducedLevelsRecipe <-
  start_recipe(TrainingSampleJoined) |>
  step_novel(all_nominal_predictors()) |>
  step_other(all_nominal_predictors(), threshold = tune()) |>
  step_dummy(all_nominal_predictors(), one_hot = TRUE) |>
  step_nzv(all_predictors())

```

## Defining workflows to evaluate

```{r}
#| eval: false

# Group 1: Simple linear models (ligeros en memoria)
WorkFlowSimple <- workflow_set(
  preproc = list(
    normalized = BasicNormalizedRecipe
  ),
  models = list(
    reg_logistic = GlmnetSpec
  )
)

# Group 2: Dimensionality reduction models (intensivos en memoria)
WorkFlowDimReduction <- workflow_set(
  preproc = list(
    pca = NormalizedPcaRecipe,
    pls = NormalizedPlsRecipe,
    umap = NormalizedUmapRecipe
  ),
  models = list(
    flex_da = FdaSpec,
    mars = EarthSpec
  )
)

# Group 3: Tree-based models (muy intensivos en memoria)
WorkFlowTrees <- workflow_set(
  preproc = list(
    reduced_levels = ReducedLevelsRecipe
  ),
  models = list(
    bag_tree = C5BagSpec,
    random_forest = RangerSpec,
    xgboost = XgboostSpec
  )
)

pin_write(
  BoardLocal,
  WorkFlowSimple,
  "WorkFlowSimple",
  type = "qs2",
  title = "Work Flow Simple"
)

pin_write(
  BoardLocal,
  WorkFlowDimReduction,
  "WorkFlowDimReduction",
  type = "qs2",
  title = "Work Flow Dim Reduction"
)

pin_write(
  BoardLocal,
  WorkFlowTrees,
  "WorkFlowTrees",
  type = "qs2",
  title = "Work Flow Trees"
)
```

## Tuning grid for each workflow

Here is the code used to train and eval de different models.

```{r}
#| eval: false
#| file: ../multicore-scripts/03a-tuning-simple-models.R
```

```{r}
#| eval: false
#| file: ../multicore-scripts/03b-tuning-dimreduction-models.R
```

```{r}
#| eval: false
#| file: ../multicore-scripts/03c-tuning-tree-models.R
```

## Exploring results

Our initial model exploration revealed that **tree-based models**, specifically Random Forest and Bagged Trees, delivered the best performance. However, a regularized Logistic Regression was a strong and much simpler contender."

Let's import the results of the exploration.

```{r}
WorkFlowTuned <- c(
  pin_read(BoardLocal, "WorkFlowSimpleTuned"),
  pin_read(BoardLocal, "WorkFlowDimReductionTuned"),
  pin_read(BoardLocal, "WorkFlowTreesTuned")
)
```

Consolidate the results for one of the metrics.

```{r}
WorkFlowTunedBest <- lapply(
  names(WorkFlowTuned),
  FUN = \(x) {
    show_best(WorkFlowTuned[[x]], metric = "brier_class") |> mutate(model = x)
  }
) |>
  do.call(what = "bind_rows")
```

Across all folds and tune params the best results came from `Random Forest` and `Bag Trees` but reguardless of their tunning params the performance was very similar so **taking more time** tunning this models to seem worthy. `Xgboost` performed poorly in general in exception of one configuration so it will be important to take more time improving the tuning params.

On the other hand, we also have the `Logistic Regression` which present a really similar results so it would be great to understand how we can **improve the model** with feature engineering.

```{r}
WorkFlowTunedBest |>
  mutate(
    best_models = case_when(
      grepl("(random|bag)_", model) ~ "group1",
      grepl("logistic|xgboost", model) ~ "group2",
      .default = "other"
    ),
    model = reorder(model, -mean, FUN = median),
  ) |>
  ggplot(aes(model, mean)) +
  geom_boxplot(aes(fill = best_models)) +
  scale_fill_manual(
    values = c(
      "group1" = Params$ColorHighlight,
      "group2" = Params$ColorHighlightLow,
      "other" = Params$ColorGray
    )
  ) +
  coord_flip() +
  labs(
    title = paste0(
      "<span style='color:",
      Params$ColorHighlight,
      ";'>",
      "**Tree Based Models**",
      "</span> ",
      "present the best performance"
    ),
    subtitle = "But the **Logistic Regression** perfomed well",
    y = "Brier Score",
    x = "Best Models"
  ) +
  theme_light() +
  theme(
    plot.title = element_markdown(size = 14),
    plot.subtitle = element_markdown(size = 12),
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.position = "none"
  )
```


## Creating workflows to explore

```{r}
# eval: false

finalize_tree_work_flow <- function(model_spec, wf_name) {
  finalized_wf =
    workflow(
      preprocessor = ConsolidationRecipe |>
        update_role(
          trip_id,
          performance_per_hour,
          percentile_75_performance,
          new_role = "additional info"
        ) |>
        step_novel(all_nominal_predictors()) |>
        step_other(all_nominal_predictors(), threshold = tune()) |>
        step_dummy(all_nominal_predictors(), one_hot = TRUE) |>
        step_nzv(all_predictors()),
      spec = RangerSpec
    ) |>
    finalize_workflow(
      select_best(
        WorkFlowTuned[["reduced_levels_random_forest"]],
        metric = "brier_class"
      )
    )

  return(finalized_wf)
}

InitialFinalizedRandomForestWf <- finalize_tree_work_flow(
  RangerSpec,
  "reduced_levels_random_forest"
)
InitialFinalizedXgboostWf <- finalize_tree_work_flow(
  XgboostSpec,
  "reduced_levels_xgboost"
)
InitialFinalizedBagTreeWf <- finalize_tree_work_flow(
  C5BagSpec,
  "reduced_levels_bag_tree"
)

InitialFinalizedLogisticWf <- workflow(
  preprocessor = ConsolidationRecipe |>
    update_role(
      trip_id,
      performance_per_hour,
      percentile_75_performance,
      new_role = "additional info"
    ) |>
    step_YeoJohnson(all_numeric_predictors()) |>
    step_novel(all_nominal_predictors()) |>
    step_dummy(all_nominal_predictors()) |>
    step_nzv(all_predictors()) |>
    step_normalize(all_numeric_predictors()),
  spec = GlmnetSpec
) |>
  finalize_workflow(
    select_best(
      WorkFlowTuned[["normalized_reg_logistic"]],
      metric = "brier_class"
    )
  )

pin_write(
  BoardLocal,
  InitialFinalizedRandomForestWf,
  "InitialFinalizedRandomForestWf",
  type = "qs2",
  title = "Initial Finalized Random Forest Wf"
)

pin_write(
  BoardLocal,
  InitialFinalizedXgboostWf,
  "InitialFinalizedXgboostWf",
  type = "qs2",
  title = "Initial Finalized Xgboost Wf"
)

pin_write(
  BoardLocal,
  InitialFinalizedBagTreeWf,
  "InitialFinalizedBagTreeWf",
  type = "qs2",
  title = "Initial Finalized Bag Tree Wf"
)

pin_write(
  BoardLocal,
  InitialFinalizedLogisticWf,
  "InitialFinalizedLogisticWf",
  type = "qs2",
  title = "Initial Finalized Logistic Wf"
)

```

## Conclusion

The initial model training and evaluation revealed two key findings:

1. **Tree-based models (`Random Forest` and `Bagged Trees`)** achieved the best performance, indicating they are well-suited to capture the complex patterns in the NYC taxi data.

2. **A simpler `Regularized Logistic Regression` model performed nearly as well**. This suggests that a strong linear relationship exists within the features, making it a highly efficient and interpretable candidate for a final model.

Therefore, the next steps should focus on two parallel paths: 

- Further tuning the `xgboost` models to maximize performance
- Investing in feature engineering to improve the already-competitive logistic model.